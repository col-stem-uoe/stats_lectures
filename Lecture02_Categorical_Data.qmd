---
title: "Lecture 2 – Describing Categorical Data "
subtitle: "Stats & Data Analysis Block<br> MSDA – IFP Programme"
author: "Javiera Alfaro Chat"
format:
  revealjs:
    theme: [default, edtheme.scss]
    include-after-body: [autoscale-tables.html, menu-projection-toggle.html]
    embed-resources: true
    fig-align: center
    fig-format: png
    slide-number: true
    slide-number-format: "c / t "   # current / total
    progress: false
    smaller: true
    menu: true
    footer: |
      <div class="custom-footer">MSDA – IFP Programme</div>
    markdown:
      extensions: +fenced_divs +attr_span
    allow-html: true
    logo: images/white_logo.png
---

## 

# Course Overview

## Week’s Learning Objectives

1.  Understand the dierent quantities used to describe the distributions of data.

2.  Understand the appropriate visualization for the distribution of categorical data.

3.  Understand methods to calculate the spread for the distribution of categorical data.

4.  Understand methods to calculate central tendency for the distribution of categorical data.

## Topics for Today

-   Last week we looked at definitions of different types of data.

-   Now we are going to move on to how we describe different types of data.

-   First, we will look at categorical variables.

## Recap: Categorical Data

:::::: fit-slide
::::: columns
::: {.column width="50%"}
### Nominal

-   No inherent order to the levels\
-   Examples:
    -   `Degree` → Architecture, Linguistics, English, Philosophy, Education ...\
    -   `Year` → 1, 2, 3, 4\
    -   `Gender` → Female, Male, Non-binary\
    -   `Exercise` → Yes, No\
    -   `Stress_level` → Low, Moderate, High\
-   Numbers used for categories are **labels only**
:::

::: {.column width="50%"}
### Ordinal

-   Values have a **meaningful order**\
-   Example: `Satisfaction_Likert_value` (1–5)
    -   1 = Very Dissatisfied\
    -   2 = Dissatisfied\
    -   3 = Neutral\
    -   4 = Satisfied\
    -   5 = Very Satisfied\
-   Higher numbers indicate greater satisfaction\
:::
:::::
::::::

## Lecture 01 Dataset {.fit-slide}

:::::: {.columns .fixer}
::: {.column .left-pane width="40%"}
-   Suppose we’re analysing a **small class sample** from our cohort.

-   The dataset has one row per student and these variables:

    -   **`ID`** = unique participant identifier\
    -   **`Degree`** = degree subject\
    -   **`Year`** = Year of study\
    -   **`Gender`** = Female / Male / Non-binary\
    -   **`Study_hours`** = average study hours per day\
    -   **`Sleep_hours`** = average sleep hours per night\
    -   **`Stress_level`** = Low / Moderate / High\
    -   **`Satisfaction_Likert_item`** = text label (Very Dissatisfied … Very Satisfied)\
    -   **`Satisfaction_Likert_value`** = numeric satisfaction (1–5)\
    -   **`Coffee_per_day`** = number of coffees per day\
    -   **`Social_media_hr`** = hours per day on social media\
    -   **`Exercise`** = Yes / No\
    -   **`Overall_mark`** = overall course mark (%)\
    -   **`IQ`** = standardised IQ score
:::

:::: {.column width="60%"}
::: table-mini
```{r, echo=FALSE, message=FALSE, warning=FALSE}
library(dplyr)
library(gt)
library(readr); library(dplyr); library(ggplot2)
students <- read_csv("data/Lecture1_data.csv", show_col_types = FALSE)

mini <- students |>
  transmute(
    ID, Degree,
    Year,Gender,
    Study_hours,
    Sleep_hours,
    Stress_level,
    Satisfaction_Likert_value,
    Coffee_per_day,
    Social_media_hr,
    Exercise,
    Overall_mark,
    IQ
  ) |>
  slice_head(n = 10)

col_head_bg   <- "#E7EEF7"
border_colour <- "#C9D4E8"
text_dark     <- "#132B4C"
text_muted    <- "#334E73"

gt(mini) |>
  # format numbers using the ORIGINAL column names
  fmt_number(columns = c(Study_hours, Sleep_hours, Coffee_per_day, Social_media_hr),
             decimals = 1) |>
  fmt_number(columns = c(Satisfaction_Likert_value, Overall_mark, IQ),
             decimals = 0) |>
  # alignment using ORIGINAL names
  cols_align(align = "center",
             columns = c(Study_hours, Sleep_hours, Satisfaction_Likert_value,
                         Coffee_per_day, Social_media_hr, Exercise,
                         Overall_mark, IQ)) |>
  cols_align(align = "left", columns = c(ID, Degree, Year,Gender, Stress_level)) |>
  # hide columns you don't want to show right now (still using original names)
  #cols_hide(columns = c(Coffee_per_day, Social_media_hr, Overall_mark, IQ)) |>
  # header & styling
  tab_header(title = md("**Data from 10 students**")) |>
  tab_style(
    style = list(cell_text(color = text_dark, weight = "bold", size = px(18))),
    locations = cells_title(groups = "title")
  ) |>
  tab_style(
    style = list(cell_fill(color = col_head_bg),
                 cell_text(color = text_dark, weight = "bold")),
    locations = cells_column_labels(everything())
  ) |>
  tab_options(
    table.font.size          = px(16),
    data_row.padding         = px(4),
    table.background.color   = "white",
    heading.background.color = "white",
    table.border.top.color   = border_colour,
    table.border.bottom.color= border_colour,
    column_labels.border.top.color    = border_colour,
    column_labels.border.bottom.color = border_colour
  ) |>
  tab_style(
    style = cell_text(color = text_muted),
    locations = cells_body()
  )

```
:::
::::
::::::

## Example Dataset {.fit-slide}

-   Today we’ll focus on **`Degree`**, **`Year`**, **`Gender`**, **`Stress_level`**, and **`Satisfaction_Likert_value`**.

::: table-mini
```{r, echo=FALSE, message=FALSE, warning=FALSE}
library(dplyr)
library(gt)

mini <- students |>
  transmute(
    ID, Degree,
    Year,Gender,
    Study_hours,
    Sleep_hours,
    Stress_level,
    Satisfaction_Likert_value,
    Coffee_per_day,
    Social_media_hr,
    Exercise,
    Overall_mark,
    IQ
  ) |>
  slice_head(n = 10)

col_head_bg   <- "#E7EEF7"
border_colour <- "#C9D4E8"
text_dark     <- "#132B4C"
text_muted    <- "#334E73"

gt(mini) |>
  # format numbers using the ORIGINAL column names
  fmt_number(columns = c(Study_hours, Sleep_hours, Coffee_per_day, Social_media_hr),
             decimals = 1) |>
  fmt_number(columns = c(Satisfaction_Likert_value, Overall_mark, IQ),
             decimals = 0) |>
  # alignment using ORIGINAL names
  cols_align(align = "center",
             columns = c(Study_hours, Sleep_hours, Satisfaction_Likert_value,
                         Coffee_per_day, Social_media_hr, Exercise,
                         Overall_mark, IQ)) |>
  cols_align(align = "left", columns = c(ID, Degree, Year,Gender, Stress_level)) |>
  # hide columns you don't want to show right now (still using original names)
  cols_hide(columns = c(Study_hours,Sleep_hours,Coffee_per_day, Exercise,Social_media_hr, IQ)) |>
  # header & styling
  tab_header(title = md("**Data from 10 students**")) |>
  tab_style(
    style = list(cell_text(color = text_dark, weight = "bold", size = px(18))),
    locations = cells_title(groups = "title")
  ) |>
  tab_style(
    style = list(cell_fill(color = col_head_bg),
                 cell_text(color = text_dark, weight = "bold")),
    locations = cells_column_labels(everything())
  ) |>
  tab_options(
    table.font.size          = px(16),
    data_row.padding         = px(4),
    table.background.color   = "white",
    heading.background.color = "white",
    table.border.top.color   = border_colour,
    table.border.bottom.color= border_colour,
    column_labels.border.top.color    = border_colour,
    column_labels.border.bottom.color = border_colour
  ) |>
  tab_style(
    style = cell_text(color = text_muted),
    locations = cells_body()
  )

```
:::

## Describing distributions

We typically want to know two things about any variable:

-   **Where the values tend to cluster**\
    → the *central point* of the distribution\
-   **How much the values vary around that point**\
    → the *spread* (or *dispersion*) of the distribution

## Let’s look at the distribution of `Degree` in our dataset

```{r, eval=TRUE, echo=FALSE}
library(readr) 
library(ggplot2) 

students <- read_csv("data/Lecture1_data.csv") 

ggplot(data = students, aes(x = Degree)) +
  geom_bar(fill = "steelblue4") +
  labs(x = "Degree", y = "Count")

```

We saw that for categorical variables we care about:

-   ***Central point*** → which category appears most often?

-   ***Spread*** → how are responses distributed across all categories?

## Let’s look at the distribution of `Degree` in our dataset

```{r, eval=TRUE, echo=FALSE}
library(readr) 
library(ggplot2) 

students <- read_csv("data/Lecture1_data.csv") 

ggplot(data = students, aes(x = Degree)) +
  geom_bar(fill = "steelblue4") +
  labs(x = "Degree", y = "Count")

```

We saw that for categorical variables we care about:

-   ***Central point*** → which category appears most often? = *MODE*

-   ***Spread*** → how are responses distributed across all categories? = How evenly or unevenly the categories are distributed

## Frequency Table for `Degree`

Sorted from most common to least common

::::: columns
::: {.column width="50%"}
```{r, echo=FALSE, message=FALSE}
library(dplyr)
library(knitr)
library(kableExtra)

# Frequency table
deg_table <- students |>
  count(Degree) |>
  mutate(
    Percent = round(n / sum(n) * 100, 1)
  ) |>
  arrange(desc(n))

# Add total row
total_row <- tibble(
  Degree = "Total",
  n       = sum(deg_table$n),
  Percent = 100
)

deg_table2 <- bind_rows(deg_table, total_row)

# Styled table
kable(
  deg_table2,
  format = "html",
  col.names = c("Degree", "Count", "Percent"),
  align = c("l", "c", "c"),
  digits = 1
) |>
  kable_styling(
    bootstrap_options = c("striped", "condensed"),
    full_width = FALSE,
    font_size = 16
  ) |>
  column_spec(1, bold = TRUE) |>
  column_spec(2:3, color = "#132B4C") |>
  row_spec(0, background = "#E7EEF7", bold = TRUE) |>    # header
  row_spec(nrow(deg_table2), bold = TRUE, background = "#F4F4F4")  # total row

```
:::

::: {.column width="45%"}
**How to read this table**

-   Linguistics is the most common Degree → this is the mode, the central point of the distribution.

-   The other categories vary in frequency:

    -   e.g., Architecture has only 7 students

    -   Linguistics has 29

-   This variation in counts across categories represents the spread of the distribution.
:::
:::::

## Frequency table for `Degree`

::::: columns
::: {.column .smaller width="50%"}
The code:

-   `count()` provides the frequency of each value\
-   `mutate()` is used to calculate new variables\
-   `round(n/sum(n) * 100, 2)`
    -   takes the column created by `count`, `n`\
    -   divides each value by the sum of counts (= sample size)\
    -   `* 100` turns it into a percent\
    -   `round(..., 2)` rounds to 2 decimal places
:::

::: {.column width="50%"}
```{r, echo=TRUE}
deg_freq <- students |> 
  count(Degree) |> 
  mutate( Percent = round(n / sum(n) * 100, 2) 
          )
deg_freq
```
:::
:::::

## Describing distributions

::::: columns
::: {.column .smaller width="50%"}
### Central tendency

-   Describes the **typical** or **most representative** value in the data.
-   For categorical data we will focus on:
    -   **Mode** → the most common category.
    -   **Median** (for ordered / ordinal categories) → the middle category once values are ranked.
:::

::: {.column .smaller width="50%"}
### Dispersion

-   Describes **how spread out** the data are around the centre.
-   For categorical / ordinal data we will look at:
    -   **Relative frequencies / proportions** of each category.
    -   **Range** and **inter-quartile range (IQR)** for ordered categories (e.g. `Year`, Likert scales).
:::
:::::

## Categorical Data

::::: columns
::: column
### Nominal variables

-   Central tendency → **Mode**

-   Variability → **Relative frequency**\
:::

::: column
### Ordinal variables

-   Central tendency → **Mode** or **Median**

-   Variability → **Range**, **Inter-quartile range (IQR)**\
:::
:::::

## Ordinal Variable: `Year`

### What can we calculate?

-   **Mode** → most common year of study

-   **Median** → middle category once ranked

-   **Range** → minimum and maximum year

```{r}
library(ggplot2)

ggplot(students, aes(x = factor(Year))) +
geom_bar(fill = "steelblue4") +
geom_vline(xintercept = median(students$Year),
colour = "firebrick", linetype = "dashed", size = 1.2) +
labs(x = "Year of Study", y = "Count",
title = "Distribution of Year with Median Marked") +
theme_minimal(base_size = 14)

```

## Calculating the median: small example

> **Median**: is the value for which half the data falls above, and half below the given value.

#### **Odd number of elements**

::::: columns
:::column
Suppose we have these **Year values**:\

:::{.narrow-table}
| Value |
|-------|
| 3     |
| 1     |
| 4     |
| 2     |
| 1     |
:::

**Step 1 – Rank order the data**\

:::{.narrow-table}
| Value |
|-------|
| 1     |
| 1     |
| 2     |
| 3     |
| 4     |
:::
:::

::: column
**Step 2 – Find the median position**\
Using the formula

$$\frac{n + 1}{2}$$ $$
\frac{5 + 1}{2} = 3
$$

So the **3rd value** in the ordered list is **2** →\
**the median is 2.**
:::
:::::

## Calculating the median: small example

#### **Even number of elements**

::::: columns
:::column
Now imagine we have six Year values:

:::{.narrow-table}
| Value |
|-------|
| 3     |
| 1     |
| 4     |
| 2     |
| 1     |
| 3     |
:::

**Step1: Rank order:**

:::{.narrow-table}
| Value |
|-------|
| 1     |
| 1     |
| 2     |
| 3     |
| 3     |
| 4     |
:::
:::

:::column 
**Step 2: Median position**:

$$\frac{n + 1}{2}$$ $$
\frac{6 + 1}{2} = 3.5
$$ 
So the median lies **between the 3rd and 4th values**:

-   3rd value = **2**
-   4th value = **3**

The median is then the **average of these values** →\

$$
\frac{2 + 3}{2} = 2.5
$$
:::
:::::

## Calculating Median: Year

-   Variable `Year` is **ordinal** (1, 2, 3, 4).
-   The **median Year** tells us the middle study year in the sample.
-   For our data:

```{r, echo=TRUE}
median(students$Year)
```

## Range: `Year`

-   The **range** of the data is simply the value between two points.
    -   We can define these points in different ways.
-   The simplest is the total range in the data (**maximum – minimum**).

```{r, echo=TRUE}
# Minimum year in the sample
min(students$Year)
```

```{r, echo=TRUE}
# Maximum year in the sample
max(students$Year)
```

```{r, echo=TRUE}
# Overall range (min and max together)
range(students$Year)
```

## Inter-quartile range: `Year`

-   The **inter-quartile range (IQR)** is the difference between the 1st and 3rd quartile.

    -   Rank the data\
    -   Split data into four equal blocks\
    -   Quartiles are the points that divide these blocks\
    -   They fall at **25%**, **50%** and **75%** of the rank-ordered data\
    -   The IQR is the **difference between 25% and 75%**

-   For **ordinal data** (like `Year`):

    -   The **first, or lower quartile** is the first category for which the cumulative percentage is ≥ 25%\
    -   The **median** is the first category for which the cumulative percentage is ≥ 50%\
    -   The **third, or upper quartile** is the first category for which the cumulative percentage is ≥ 75%

## What is cumulative percentage?

-   Remember our percentage calculations?
-   Well, imagine stacking these on top of one another...

```{r, echo=TRUE}
students |> 
  count(Year) |> 
  mutate( 
    Percent = round((n / sum(n)) * 100, 2), 
    Cumulative = cumsum(Percent) ) 
```

## Inter-quartile range: `Year`

-   IQR is a **summary statistic**:

::::: {.text-center}\
**IQR = Q3 − Q1**\
:::::

It gives **one value** representing how spread out the middle 50% of the data are.

Example:

-   Q1=2

-   Q3=3

Then:

::::: {.text-center}\
**IQR = Q3 − Q1**\
:::::

So the **IQR = 1**.

## Inter-quartile range: `Year` in R

-   We can calculate the IQR directly using the function `IQR()`
-   Or calculate specific quantiles using the `quantile()` function

```{r, echo=TRUE}
# 25th and 75th percentiles for Year
quantile(students$Year, c(.25, .75))
```

-   So the 25th percentile is the lower quartile (Q1) The 75th percentile is the upper quartile (Q3)

```{r, echo=TRUE}
# Inter-quartile range

IQR(students$Year)

```

-   The IQR is **Q3 − Q1** (the spread of the middle 50% of the data)

## Ranks and order

-   Notice how both the **median** and the **IQR** make use of **ranked data**

-   **Ranked** = ordered

-   This is why we use these measures with **ordinal data** such as `Year`

# Plotting

## Example Bar Plot : `Gender`

::::: columns
::: {.column width="50%"}
-   Take `Gender` in our class data (N =`nrow(students)`).

-   Count how many Female, Male, and Non-binary students we have.

-   Show this with a simple bar plot.

    ```{r, echo=FALSE}
    students |>
      count(Gender) |>
      kable(col.names = c("Gender", "Count"))
      
    ```
:::

::: {.column width="50%"}
```{r}
library(ggplot2)

ggplot(students, aes(x = Gender)) + 
  geom_bar(fill = "steelblue4") + 
  labs(x = "Gender", y = "Count") + 
  scale_y_continuous(limits = c(0, 100)) +
  theme_minimal(base_size = 14)

```
:::
:::::

## Plotting Fundamentals

-   There are many types of graph; each summarises a different kind of data or relationship.

-   First, a quick reminder of the grammar of graphics we’ll use.

## Plotting Fundamentals

-   **Data** supply the values we visualise.

-   **Aesthetics** map variables to visual properties (x, y, fill, size).

-   **Axes** have **scales** that convert data to positions/values on the canvas.

-   **Geoms** (bars, points, lines) draw the shapes you see.

## Bar Plot

::::: columns
::: {.column width="50%"}
-   Bar plots display **frequency distributions** of **categorical** variables.

-   Our example:

    -   **Data** = `Gender` in `students`.

    -   **X-axis** = values of a variable, in this case:

        -   categories of `Gender` (Female, Male, Non-binary).

        -   Scale = three discrete values.

    -   **Y-axis** = Frequency (count).
:::

::: {.column width="50%"}
```{r, echo=TRUE}

ggplot(students, aes(x = Gender)) + 
  geom_bar(fill = "steelblue4") + 
  labs(x = "X-axis = Gender", y = " Y-axis = Count") + 
  scale_y_continuous(limits = c(0, 100)) +
  theme_minimal(base_size = 14)
```
:::
:::::

## Bar Plot: The CODE

::: bigcode
```{r, eval=FALSE, echo=TRUE}
ggplot(students, aes(x = Gender)) + 
  geom_bar(fill = "steelblue4") + 
  labs(x = "Gender", y = "Count") + 
  scale_y_continuous(limits = c(0, 100)) +
  theme_minimal(base_size = 14)

```
:::

<br>

::::: columns
::: {.column width="50%"}
-   **`ggplot()`**: starts the plot

-   **`aes()`**: maps variables to parts of the plot (here: Gender → x-axis)

-   **`geom_bar()`**: draws bars showing counts

-   **`fill =`**: chooses the colour of the bars

-   **`labs()`**: labels the axes

-   **`scale_y_continuous()`**: controls the y-axis range

    -   **`scale_y_continuous(limits = c(0, 100))`** Forces the y-axis to run from **0 to 100**.

-   **`theme_minimal()`**: cleans up the overall style of the plot

-   **`base_size = 14`** : Font size
:::

::: {.column width="50%"}
```{r}

ggplot(students, aes(x = Gender)) + 
  geom_bar(fill = "steelblue4") + 
  labs(x = "Gender", y = "Count") + 
  scale_y_continuous(limits = c(0, 100)) +
  theme_minimal(base_size = 14)

```
:::
:::::

## Bar Plot for `Degree`

> What is the CODE doing?

-   line 1 ?
-   line 2 ?
-   line 4 ?

```{r, eval=FALSE, echo=TRUE}
library(readr) 
library(ggplot2) 

students <- read_csv("data/Lecture1_data.csv") 

ggplot(data = students, aes(x = Degree)) +
  geom_bar(fill = "steelblue4") +
  labs(x = "Degree", y = "Count")

```

## Summary of today

-   **To describe nominal data we use**
    -   Bar plots
    -   Mode
    -   Frequency tables
-   **To describe ordinal data we use**
    -   Bar plots
    -   Mode or median
    -   Range (total, IQR)

# This Week

-   Attend your lab and complete lab tasks collaboratively\
-   Office hours for 1-to-1 questions\
